{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an outline of a Jupyter Notebook to guide you in classifying jaguar habitat using location data and an 8-band satellite image. The Python libraries used in this notebook are pandas, rasterio, geopandas, numpy, and sklearn. This Jupyter Notebook provides a method for classifying jaguar habitat in satellite imagery using location data from a CSV file. The RandomForestClassifier is used as the classification model, but other classifiers can also be tested to see if they provide better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file containing jaguar location data and convert it to a GeoDataFrame.\n",
    "csv_file = 'jaguar_locations.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 8-band satellite image using rasterio.\n",
    "satellite_image = 'satellite_image.tif'\n",
    "with rasterio.open(satellite_image) as src:\n",
    "    image = src.read()\n",
    "    profile = src.profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a function to extract pixel values for each jaguar location.\n",
    "def extract_pixel_values(gdf, raster):\n",
    "    values = []\n",
    "    for point in gdf.geometry:\n",
    "        row, col = raster.index(point.x, point.y)\n",
    "        pixel_values = raster.read()[:, row, col]\n",
    "        values.append(pixel_values)\n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract pixel values for each jaguar location using the function.\n",
    "X = extract_pixel_values(gdf, src)\n",
    "y = gdf['habitat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train a RandomForestClassifier model on the training data.\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict the habitat classes on the testing set and calculate the accuracy score.\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a confusion matrix to evaluate the model's performance.\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the model to the entire satellite image to classify jaguar habitat.\n",
    "def classify_image(image, clf):\n",
    "    img_shape = image.shape\n",
    "    flattened_image = image.reshape(img_shape[0], -1).T\n",
    "    classified_data = clf.predict(flattened_image)\n",
    "    classified_image = classified_data.reshape(img_shape[1], img_shape[2])\n",
    "    return classified_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the classified image as a GeoTIFF file.\n",
    "classified_image = classify_image(image, clf)\n",
    "profile.update(dtype=rasterio.uint8, count=1)\n",
    "output_file = \"classified_habitat.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "    dst.write(classified_image.astype(rasterio.uint8), 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are five popular satellite image classification techniques used for habitat analysis, along with a short description of each method, their strengths, and weaknesses:\n",
    "\n",
    "## Supervised Classification: Maximum Likelihood Classification (MLC)\n",
    "\n",
    "Method: A parametric method based on the Bayesian probability theory that assumes each class follows a Gaussian distribution. It calculates the likelihood of a pixel belonging to each class and assigns the pixel to the class with the highest likelihood.\n",
    "\n",
    "Strengths: Robust when assumptions of normality and equal covariance matrices hold, and it can handle a large number of classes.\n",
    "\n",
    "Weaknesses: Sensitive to the violation of normality assumptions, and it requires a large number of training samples to estimate covariance matrices accurately.\n",
    "\n",
    "## Supervised Classification: Random Forest (RF)\n",
    "\n",
    "Method: An ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes predicted by individual trees. It uses a subset of features for each tree to reduce correlation between trees.\n",
    "\n",
    "Strengths: Handles overfitting well, requires little preprocessing, handles missing data, and can handle a large number of features.\n",
    "\n",
    "Weaknesses: Less interpretable than single decision trees, longer training time, and can be biased if some classes dominate the dataset.\n",
    "\n",
    "## Unsupervised Classification: K-means Clustering\n",
    "\n",
    "Method: A clustering technique that partitions the dataset into K clusters based on the mean distance between data points and cluster centroids. The algorithm iteratively updates the centroids until convergence.\n",
    "\n",
    "Strengths: Simple and fast, works well when clusters have similar sizes, and can handle large datasets.\n",
    "\n",
    "Weaknesses: Requires the number of clusters to be defined beforehand, sensitive to the initial placement of centroids, and can converge to local minima.\n",
    "\n",
    "## Object-Based Image Analysis (OBIA)\n",
    "\n",
    "Method: A two-step approach that first segments the image into groups of connected pixels (objects) based on spectral and spatial characteristics, and then classifies these objects using supervised or unsupervised techniques.\n",
    "\n",
    "Strengths: Better suited for high-resolution imagery, more accurate classification in heterogeneous landscapes, and can incorporate contextual information.\n",
    "\n",
    "Weaknesses: Requires complex preprocessing, computationally expensive, and parameter selection can be challenging.\n",
    "\n",
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Method: A type of deep learning model that uses convolutional layers to extract features from the input image. The model learns to recognize patterns and classify images by training on labeled data.\n",
    "\n",
    "Strengths: Can learn complex features automatically, performs well with large training datasets, and can handle high-dimensional data.\n",
    "\n",
    "Weaknesses: Requires a large amount of labeled data, computationally intensive, and less interpretable than other methods.\n",
    "\n",
    "\n",
    "These techniques each have their own strengths and weaknesses, so the choice of method depends on factors like the size and type of the dataset, computational resources available, and the specific requirements of the habitat analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method using 10x10 pixel chips\n",
    "\n",
    "\"\"\"\n",
    "This code reads the CSV file and satellite image, extracts 10x10 pixel chips, reshapes the chips into 1D feature vectors, splits the data into training and testing sets, trains a Random Forest classifier on the training data, and evaluates the classifier's performance on the test data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Function to extract pixel chips\n",
    "def extract_pixel_chips(gdf, raster, chip_size=10):\n",
    "    half_chip = chip_size // 2\n",
    "    values = []\n",
    "    for point in gdf.geometry:\n",
    "        row, col = raster.index(point.x, point.y)\n",
    "        pixel_values = raster.read()[:, row-half_chip:row+half_chip, col-half_chip:col+half_chip]\n",
    "        values.append(pixel_values)\n",
    "    return np.array(values)\n",
    "\n",
    "# Read CSV and create GeoDataFrame\n",
    "csv_file = 'jaguar_locations.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "# Read satellite image\n",
    "satellite_image = 'satellite_image.tif'\n",
    "with rasterio.open(satellite_image) as src:\n",
    "    image = src.read()\n",
    "    profile = src.profile\n",
    "\n",
    "# Extract pixel chips and labels\n",
    "X = extract_pixel_chips(gdf, src)\n",
    "y = gdf['habitat'].values\n",
    "\n",
    "# Reshape the pixel chips into 1D feature vectors (input_channels * chip_size * chip_size)\n",
    "input_channels = X.shape[1]\n",
    "X = X.reshape(X.shape[0], input_channels * 10 * 10)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the habitat class for test data and evaluate performance\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
