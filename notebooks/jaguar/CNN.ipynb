{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def extract_pixel_chips(gdf, raster, chip_size=10):\n",
    "    half_chip = chip_size // 2\n",
    "    values = []\n",
    "    for point in gdf.geometry:\n",
    "        row, col = raster.index(point.x, point.y)\n",
    "        pixel_values = raster.read()[:, row-half_chip:row+half_chip, col-half_chip:col+half_chip]\n",
    "        values.append(pixel_values)\n",
    "    return np.array(values)\n",
    "\n",
    "class HabitatCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(HabitatCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(32 * 5 * 5, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, X_test, y_test, num_epochs=100):\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(X_test)\n",
    "            loss = criterion(output, y_test)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Test Loss: {test_losses[-1]}\")\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "csv_file = 'jaguar_locations.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "\n",
    "satellite_image = 'satellite_image.tif'\n",
    "with rasterio.open(satellite_image) as src:\n",
    "    image = src.read()\n",
    "    profile = src.profile\n",
    "\n",
    "X = extract_pixel_chips(gdf, src)\n",
    "y = gdf['habitat'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "input_channels = X.shape[1]\n",
    "model = HabitatCNN(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the classified result as a new GeoTIFF, you'll need to predict the habitat class for each 10x10 pixel chip in the satellite image and then merge the classified chips into a single raster. Here's how you can do that:\n",
    "\n",
    "Create a function to split the entire satellite image into 10x10 pixel chips with a stride (step) equal to the chip size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_into_chips(image, chip_size=10):\n",
    "    chips = []\n",
    "    rows, cols = image.shape[1], image.shape[2]\n",
    "    for row in range(0, rows, chip_size):\n",
    "        for col in range(0, cols, chip_size):\n",
    "            chip = image[:, row:row+chip_size, col:col+chip_size]\n",
    "            chips.append(chip)\n",
    "    return np.array(chips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the entire satellite image into 10x10 pixel chips:\n",
    "image_chips = split_image_into_chips(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the habitat class for each chip:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    image_chips_tensor = torch.tensor(image_chips, dtype=torch.float32)\n",
    "    predictions = model(image_chips_tensor).argmax(dim=1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the predictions into the original image shape:\n",
    "classified_image = predictions.reshape(image.shape[1] // 10, image.shape[2] // 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classified image as a new GeoTIFF:\n",
    "output_file = 'classified_jaguar_habitat.tif'\n",
    "\n",
    "output_profile = profile.copy()\n",
    "output_profile.update(\n",
    "    dtype=rasterio.uint8,\n",
    "    count=1,\n",
    "    compress='lzw'\n",
    ")\n",
    "\n",
    "with rasterio.open(output_file, 'w', **output_profile) as dst:\n",
    "    dst.write(classified_image.astype(rasterio.uint8), 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this method assumes that the input satellite image's dimensions are divisible by the chip size (10x10 pixels in this case). If the dimensions are not divisible, you might need to pad the image to make it divisible or handle the border cases separately.\n",
    "\n",
    "Also, this method predicts the habitat class for each 10x10 pixel chip independently, without considering the spatial relationship between neighboring chips. If you need a more accurate classification that considers the spatial context, you can try using a sliding window approach or a Fully Convolutional Network (FCN) for semantic segmentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
